{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b15ab9a2-2167-4020-bd41-b0db57b908cf",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Tokenization is at the heart of some of the main issues with LLMs.\n",
    "1. LLMs can not spell words.\n",
    "2. LLMs truggle with super simple string tasks like reversing a string.\n",
    "3. Why are LLMs worse at non-English languages ?\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef378b0-42bb-41f8-b10f-8c234321b7e0",
   "metadata": {},
   "source": [
    "Try out tokenization for different LLms here:\n",
    "\n",
    "https://tiktokenizer.vercel.app/?model=codellama%2FCodeLlama-70b-hf\n",
    "\n",
    "## Notes:\n",
    "1. Space is sometimes included as part of a token\n",
    "2. Digits are also tokenized.\n",
    "3. Tokenization is case sensitive.\n",
    "4. We have more data in english than in non-english, so english sentences have longer tokens due to this abundance. So a longer context can be fed into a model for a given number of context length.\n",
    "5. GPT2 is not very good with python. One of the reasons is that the spaces are treated as different tokens. We run out of the context length. GPT4 tokenizer handles python much better, as it groups together the white spaces, which was a deliberate choice made by openAI. \n",
    "6. Increasing the vocab size is not always good, since it increases the embedding table size and at the output, it affects the performance of softmax layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc9b98-cb62-4c26-97bb-3ac3ec27a18b",
   "metadata": {},
   "source": [
    "## Unicode Encoding\n",
    "- Unicode system includes almost 150, 000 characters across 161 scripts, what they look like and what integer represents them. We can access the unicode code point using the \"ord\" function in python.\n",
    "-  Why can't we use this coding natively for tokenization?\n",
    "    The vocab would be very largeThe unicode encoding keeps changing.\n",
    "    The unicode encoding keeps changing.\n",
    "- The unicode encoding is how the standard abstacted codes for characters are translated and stored as into sequences of bytes. UTF-8 (most common), UTF-16, UTF-32.\n",
    "- UTF-8 encoding takes each of the code point and translates it into a byte stream from 1 to 4 bytes (variable length encoding). UTF-32 is fixed length.\n",
    "- UTF-8 is preferred because it is backward compatible into much simpler Â ASCII encoding.\n",
    "- UTF-16 and UTF-32 are somewhat wasteful as they have a lot of 0's between them.\n",
    "- We cannot use these encodings naively because although they would ensure a finite embedding table of size 256 and smaller output size, but we would run out of context length.\n",
    "- Readings: A programmers introduction to Unicode,  UTF-8 everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a33dc81-f3ef-4cb5-a50a-8c56d72226b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"f\") # We can't plug in a string  here. It expects a single character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03e1408-b8d7-4274-b7ac-4b2dc4a86da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104, 101, 108, 108, 111]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of raw bytes of utf-8 encoding \n",
    "list((\"hello\").encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5239ca-5a06-4819-876f-6f10b8521fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
